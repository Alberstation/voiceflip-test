# -----------------------------------------------------------------------------
# RAG AI Engineer — Environment variables (all parameters documented)
# Copy to .env and set values. Run everything via Docker; no local installs.
# -----------------------------------------------------------------------------

# ----- Hugging Face (required for Phase 2) -----
# Get a free token at https://huggingface.co/settings/tokens
HUGGINGFACEHUB_API_TOKEN=

# ----- Qdrant -----
QDRANT_HOST=vectordb
QDRANT_PORT=6333
# Qdrant collection name
QDRANT_COLLECTION_NAME=real_estate_rag

# ----- Paths (inside container) -----
# Directory with DOCX/HTML documents
DOCS_DIR=/app/docs
# Excel with document list and chunking type per file
DOCS_METADATA_XLSX=/app/Real_Estate_RAG_Documents.xlsx

# ----- Embeddings (Hugging Face Inference API) -----
# Model: BAAI/bge-small-en-v1.5 (384 dim) recommended for retrieval
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DIM=384
EMBEDDING_BATCH_SIZE=16
EMBEDDING_TIMEOUT_SEC=30
EMBEDDING_RETRIES=1

# ----- Retrieval: Similarity Top-k -----
RETRIEVAL_TOP_K=5
RETRIEVAL_SIMILARITY_THRESHOLD=0.25

# ----- Retrieval: MMR -----
RETRIEVAL_MMR_FETCH_K=20
RETRIEVAL_MMR_K=6
RETRIEVAL_MMR_LAMBDA=0.7

# ----- LLM (Hugging Face Inference API) -----
LLM_MODEL=Qwen/Qwen2.5-1.5B-Instruct
LLM_MAX_NEW_TOKENS=350
LLM_TEMPERATURE=0.2
LLM_TOP_P=0.9
LLM_TIMEOUT_SEC=60
LLM_RETRIES=1

# ----- Chunking (overlap strategy default) -----
CHUNK_SIZE=512
CHUNK_OVERLAP=64

# ----- Text cleaning -----
# Max consecutive newlines to keep (collapse \n{3,} -> \n\n)
CLEAN_MAX_CONSECUTIVE_NEWLINES=2

# ----- Eval (RAGAS) — optional -----
# Stronger LLM for RAGAS judge (1.5B produces unreliable scores). E.g. mistralai/Mistral-7B-Instruct-v0.2
# EVAL_LLM_MODEL=
# Higher max tokens for eval LLM (RAGAS needs longer output; 350 causes LLMDidNotFinishException)
# EVAL_LLM_MAX_NEW_TOKENS=1024
# Skip context_precision (its statement_generator often fails schema validation with HF models)
# EVAL_SKIP_CONTEXT_PRECISION=true

# ----- Optional -----
LOG_LEVEL=INFO

# ----- OpenClaw (Phase 6) — optional -----
# Gateway URL (e.g. http://localhost:18789 when OpenClaw runs on host)
# OPENCLAW_GATEWAY_URL=
# Token from OpenClaw setup (docker-setup.sh or openclaw onboard)
# OPENCLAW_GATEWAY_TOKEN=
